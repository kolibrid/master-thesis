We have developed GeneNet VR, a virtual reality application for the visualization of genetic networks. We used two datasets that contain genetic information that belong to a woman with breast cancer; one dataset from a tissue and another from a blood sample. These datasets come from the MIxT project (Matched Interaction Across Tissues), were they provide a network view in 2-dimensions for the visualization of these datasets. In GeneNet VR we move this network view to the virtual reality and enhance the visualization process by making the most of VR.

In GeneNet VR, we have focused on the visualization and interactivity experience, where the user can explore these type of networks from a novel perspective. The application is developed in Unity, using a Oculus Quest standalone headset.
We can see in the application a network of nodes in 3D. Each node correspond to a gene from the dataset, and they are organized in clusters and colours. The user has the possibility to move around the scene using a VR locomotion technique called teleportation. It's also possible to look around the scene by rotating the camera to the right or the left using the controllers. This gives the user the possibility to explore the network without having to walk around the real world and therefore reducing motion sickness problems, which are common un VR.

The application offers interaction features like the selection of nodes using a laser pointer. When a node is selected, the name of the node is shown and a set of lines are rendered in the scene, corresponding to the relationships from the node to other nodes of the dataset. The user has also the possibility to scale up and down the network, translate the network to other position in the scene, filter nodes using a menu and morph the network from one dataset to the other one, allowing the user compare both networks at the same time.

We have evaluated the performance and scalability of GeneNet VR in order to know if it meets the Oculus' performance guidelines and if larger datasets could be visualized. We focused on evaluate the translation and scale of the network as well as the node selection.  We could see that the average delta time oscilates between 6.4 and 8.7 milliseconds in the experiments, which is pretty good. We couldn't determine if the number of nodes and the number of edges to render in the scene could have a big impact in the scalability of the network. A reason for this is that it was hard to isolate these characteristics, since Unity is a complex 3D egine and many processes happen at the same time. In addition we also compared the performance of GeneNet VR in the Oculus Quest Hardware and in the PC hardware. We could see that the performance for the Oculus Quest was slightly worse than on the PC, but still inside of the Oculus' performance guidelines.

All in all, we concluded that using virtual reality for the visualization of abstract networks of data like the ones from MIxT have some benefits. We could see that the interaction in VR can feel more natural for the users because they use their hands. We can also implement some gestures that most people already know (like stretching the network to scale it or pulling from the network to move it around) in order to accelerate the learning process. In addition, VR offers the possibility to add 2D interfaces like menus, which enhances the interactivity and adds multiple interactive possibilities. Some downsides that we we could see in using VR are mostly related to motion sickness and unconformity of using a headset like Oculus Quest.
