I will focus in this chapter on similar works found in the literature for the visualization of bioinformatics data in VR.

\section{Virtual Reality Chemical Space}
Virtual Reality Chemical Space is a VR application for the interactive exploration of chemical space populated by Drugbank compounds\cite{drugbank}. It is also developed in Unity using C\# and the VRTK library. They use a particle system to render the particles of the chemical space. To render the particles, they use shaders instead of geometrical spheres as well, optimizing the number of vertices per datapoint in the scene. In order to reduce motion sickness, they have introduced a floor in the form of a grid acting as a static frame of reference. Also instead of letting the user move through the VR environment, they use a controller to move the point cloud. In Figure \ref{fig:drugbank} we can see a screenshot from the VR application. As we can notice in the screenshot, there is a subtle rendering of an outer space scene as an independent visual background. This is another technique to reduce motion sickness that helps the user keep the notion of space. This is an interesting technique that we could have tried in GeneNet VR.

They conclude in the article that the application that they have developed doesn't visualize an environment with an analog in the real world, but instead a mathematical construct. Also, some of the drawbacks that VR has compared to traditional solutions is that the VR headsets are not so comfortable as well as often-occurring eye strain and virtual reality sickness. They also conclude that the application of VR in chemistry has more potential in the fields of education and training than for the current state of technology. The tools for chemistry need to be further evaluated whether they should be extended to VR.

\begin{figure}[h!]
    \centering%
    \includegraphics[width=\textwidth]{drugbank}
    \caption{Optimized virtual reality chemical space. Figure taken from \cite{drugbank}.}
    \label{fig:drugbank}
\end{figure}%

\section{BioVR}
BioVR is an interactive VR platform for integrated visual analysis of DNA/RNA protein structures\cite{biovr}. It is built in Unity and using C\#. The headset that they targeted the application to is Oculus Rift. One big difference between BioVR and our application is that in BioVR they use the hands for the interactions rather than the controllers. This can be very attractive and it could have worked very well for GeneNet VR since most of the interactions can be done with hand gestures. Also since early 2020, hand tracking has been integrated into Oculus Quest, making it easier for dveleopment\footnote{https://developer.oculus.com/documentation/unity/unity-handtracking}.
A screenshot of BioVR can be seen in Figure \ref{fig:biovr}. The user in BioVR can visualize the virtual hands in the virtual world and they are used for the interaction with the nucleotide sequence and UI menus. In GeneNet VR instead of the hands, we show the controllers, which help the user orientate in the space. The research concludes that using VR helps in create new workflows for researchers to view DNA/RNA sequence and protein structures. Also, in VR it is easy to integrate 2D user interfaces in the virtual world, which can be very helful for users as we can see in Figure \ref{fig:biovr} B.

\begin{figure}[h!]
    \centering%
    \includegraphics[width=\textwidth]{biovr}
    \caption{Screenshot from BioVR. Figure taken from \cite{biovr}.}
    \label{fig:biovr}
\end{figure}%

\section{CellexalVR}
CellexalVR is a virtual reality environment for the visualization and analysis of single-cell RNAseq experiments that help researchers understand their data\cite{cellexalvr}. The system is divided into two parts: the first one consists of the VR interface and the second is an R package called cellexalvrR that does back-end calculations and also provides functions that allows the user to export the scRNAseq data from an R session for CellexalVR to read. CellexalVR was developed in Unity for HTC Vive (Pro). They used Unity and C\# and R for the implementation. They used libraries like VRTK, OpenVR, and SteamVR as well in the implementation.

Something that is interesting in CellexalVR is that it allows a multi-user mode via the Photon Unity Networking. This works by sending information about the events to each user using Remote Procedure Calls. In Figure \ref{fig:cellexavr} we can see a screenshot from CellexalVR where two users participate in the same session. Other users can also be in the same session but just be watchers and be in like a "ghost mode". This is something interesting that could be used in GeneNet VR as well. Especially the "ghost mode" could be useful so that other people can visualize the network at the same time from other perspectives.

\begin{figure}[h!]
    \centering%
    \includegraphics[width=\textwidth]{cellexavr}
    \caption{Screenshot from CellexalVR. Two users using CellexalVR at the same time. The head models were taken from NASA. Figure taken from \cite{cellexalvr}.}
    \label{fig:cellexavr}
\end{figure}%

\section{BigTop}
BigTop is a visualization framework in VR for the rendering of Manhattan plots in three dimensions\cite{bigtop}. Manhattan plots are usually 2-dimensional, where genomic coordinates are displayed on the x-axis and the negative log-10 of the association P-value for each single nucleotide polymorphism (SNP) displayed on the Y-axis. Each dot on the Manhattan plot signifies an SNP then. In BigTop, the z-axis is used to display the minor allele frequency of each SNP. This allows the identification of allelic variants of genes. As for the interaction, BigTop allows the user to select a node in order to obtain more information like the SNP name. BigTop is built in JavaScript with the React and A-Frame frameworks. It can also be rendered in any commercially available VR headsets and also in 2D web browsers.

To move around the scene in BigTop the user can take steps (in the VR version) or using the arrow keys from the keyboard. The user can select the nodes by pointing with a laser at the nodes in the scene in the VR version (See Figure \ref{fig:bigtop} for a screenshot of BigTop showing the selection of a node). In the browser version, it is possible to select them using the pointer from the mouse. Also in order to look around, the user needs to move the head around using the VR headset, or by using click and drag with the mouse (in the browser). In GeneNet VR we have focused only on building a visualization system for a VR headset. We have used better locomotion techniques that improve the comfortability. However, the locomotion technique that they use to move around could be a good idea for GeneNet VR as well.

\begin{figure}[h!]
    \centering%
    \includegraphics[width=\textwidth]{bigtop}
    \caption{Screenshot from BigTop where a node is selected. Figure taken from \cite{bigtop}.}
    \label{fig:bigtop}
\end{figure}%

\section{Unity vs Unreal Engine}
Unity3D\footnote{https://unity.com} and Unreal Engine\footnote{https://www.unrealengine.com} are two popular software for the development of videogames as well as virtual reality games and other applications. They offer integration for Oculus Quest and other VR devices in the market.

I chose Unity for the development mostly because I had some experience with it. In addition, when I researched VR development, I found that Unity is well integrated with Oculus Quest and there is the VRTK library. I also found several tutorials about VR development in Unity as well as documentation for the Oculus integration and about VRTK. Unity is also known to be easier to learn. There is a study where they teach Unity and Unreal Engine to students, and they concluded that Unity is a little less complicated to learn \cite{unity_vs_unreal}. On the other hand, Unreal can create more professional-looking results. For this project, we are not looking for realistic graphics, since we are dealing with abstract data.

\section{VR toolkits and frameworks}
%There are not many libraries available for VR development for Oculus.
Apart from the Oculus integration for Unity, there are some 3rd party toolkits and frameworks that we can use to accelerate the development process for VR. I used VRTK in my project, as I have mentioned before. This toolkit contains several scripts and prefabs that can be used to build several VR solutions. In my case, I used this library to build the teleportation and snap rotation locomotion techniques. VR Interaction Framework\footnote{http://beardedninjagames.com/vr-framework} is another toolkit for VR development, but it is not open source. In addition, Unity comes with XR, support for XR platform integration.

\section{VR headsets}
We can find numerous VR headsets nowadays in the market\footnote{https://versus.com/en/vr-headset}, from simple headset solutions like Google Cardboard to more advanced ones like HTC Vive Focus. In order to choose which headset we wanted to target our application to, we had into account the price, performance, and features that the headsets have. We chose Oculus Quest because the price was not very high (5799,- kr in 2019) and it was also a standalone device, which is not so common among the VR headsets. Oculus Quest also has an advantage as for the performance, it can be connected to a PC where we can run heavier applications. In this way, this headset is very versatile and the price is affordable for many people and especially for research entities. Other features that Oculus Quest has is that it comes with two controllers that have free movement and inputs as buttons, triggers and grips that can be used for the interactions in the VR application. Other headsets from a lower price range like the Oculus Go have fewer inputs in the controllers and are more stationary.
