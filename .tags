Locomotion	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/bignetvr.tex	/^\\end{figure}%$/;"	subsubsection	line:48
Scalable network in Unity and data structures	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/bignetvr.tex	/^Finally, our dataset has information about the relationships between the nodes. BigNet VR is implemented to show also this information. Because there can be too many relationships in the dataset, we don't show them all at the same time. Therefore we can only see those of the node that the user has selected. The way that these relationships are represented is with lines between the nodes.$/;"	section	line:100
Other features of BigNet VR	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/bignetvr.tex	/^The algorithm used to cluster the nodes in the network is another important aspect that can influence in the scalability. In BigNet VR we use a linear algorithm that clusters the nodes in the 3d space depending on the module where they belong too. In this way the user can visualize each module as single clusters with a distinct colour per cluster.$/;"	section	line:165
New requirements based on the interviews	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/futureWork.tex	/^Finally, we would also like to run other experiments to further evaluate the performance of the application and study better the scalability. We would like to use larger datasets in order to determine where is the size limit for which we can visualize these datasets in GeneNet VR for both PC and the Oculus Quest headset.$/;"	section	line:15
MIxT in VR	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/mixt.tex	/^\\end{figure}$/;"	section	line:30
Network characteristics	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/mixt.tex	/^We have added the possibility to compare two datasets in real-time in GeneNet VR. This can be very useful for bioinformaticians when they work with several datasets like in MIxT. To compare two networks, the user can use a UI slider to visualize two datasets at the same time, creating what we call a morphing effect. To help the user distinguish from one dataset to another, we use linear interpolation for both the color of the nodes and their position.$/;"	section	line:39
Virtual Reality Chemical Space	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/related-work.tex	/^I will focus in this chapter on similar works found in the literature for the visualization of bioinformatics data in VR.$/;"	section	line:1
Challenges and research problem	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/introduction.tex	/^\\textbf{Thesis statement: } \\emph{Virtual Reality is advantageous for the visualization of large biological networks and for rapid exploration of patterns in them using affordable hardware}.$/;"	section	line:36
Proposed solution and contribution	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/introduction.tex	/^The interactivity in VR is usually done with the VR controllers, which simulate our hands in the virtual world. We can implement natural actions for the operator such as grabbing objects or items with their hands, which will feel intuitive. However, we can also implement other actions in the virtual world like using laser pointers to select something, using 2D menus inside the virtual world or teleporting the user to other parts of the virtual space. In GeneNet VR, we are dealing with abstract information and the amount of data can escalate quickly if we do not implement practical solutions. We must therefore maintain a proper balance between the amount of data being visualized, comfort and user-friendly interaction solutions and good performance.$/;"	section	line:71
Outline	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/introduction.tex	/^\\end{figure}$/;"	section	line:92
csv	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/scripts/cdf.py	/^import csv$/;"	namespace	line:1
collections	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/scripts/cdf.py	/^import collections$/;"	namespace	line:2
number_nodes	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/scripts/cdf.py	/^number_nodes = list()$/;"	variable	line:4
number_edges	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/scripts/cdf.py	/^number_edges = list()$/;"	variable	line:5
cum_edges	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/scripts/cdf.py	/^cum_edges = list()$/;"	variable	line:6
total_num_edges	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/scripts/cdf.py	/^total_num_edges = 0$/;"	variable	line:7
previous_value	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/scripts/cdf.py	/^previous_value = 0$/;"	variable	line:8
csv_reader	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/scripts/cdf.py	/^    csv_reader = csv.reader(csv_file, delimiter=' ')$/;"	variable	line:11
f	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/scripts/cdf.py	/^f = open(".\/data\/bloodEdgesCDF.dat", "w+")$/;"	variable	line:24
Methodology of experiment setup	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/evaluation.tex	/^\\end{enumerate}$/;"	section	line:30
Translating the network meets the 72 FPS	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/evaluation.tex	/^The average of all the frames is the most important value to look at because it can give us an idea of whether the experiment meets the required FPS or not. In a perfect application where all the frames last the same amount of time and where the frame rate is 72, each frame would last around 13.9 milliseconds. However, this is not the case in real applications. If the general average is above 13.9 milliseconds, it means that the experiment didn't pass the 72 FPS. By looking at the 0.25\\% worst frame time and the 1\\% worst frame time, we will get the frame with the worst time and the 7 frames with the worst times respectively (our experiments last for 700 frames). If we see that these frames have much worse times, compared with the general average, we will use a profiler to see if there are bottlenecks and try to give a solution to them.$/;"	subsubsection	line:122
Selecting nodes the network meets the 72 FPS but with possible bottlenecks	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/evaluation.tex	/^The average time for this experiment is also under the 13.9 milliseconds limit, meaning that the interaction reaches 72 FPS. The low 1\\% is also under 13.9 milliseconds, so we don't consider that there are any big issues for the performance of this interaction. The variation among the network sizes is also insignificant. An evaluation with bigger networks would be necessary to determine the network size limit for which the performance is not good.$/;"	subsubsection	line:165
What network properties influence the scalability	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/evaluation.tex	/^One important observation is that in the experiment we just select 7 nodes, one every 100 frames. However, when we use GeneNete VR, it's easy to select many nodes in just a few frames. This is because the select node function is run for every frame when we trigger the action for it, and if we point at a region where there are many nodes together, it will be easy to select several of them in a short period of time. Also, not all nodes have the same number of edges. It would be interesting to know if the number of edges could decrease the performance as well. We will analyze in the following section if the number of edges could have more impact on the performance and scalability of the network.$/;"	section	line:260
Do we achieve the recommended FPS 72 for large biological networks when using the standalone Oculus Quest	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/evaluation.tex	/^It's hard to determine from the experiments that we ran if the number of edges can have an impact on the scalability of the system. We would need to better isolate this part of the code and further evaluate it. However, we expect that the number of edges can have an impact. As we have mentioned before, a better implementation solution could improve the performance of this. Instead of creating the edges in the scene every time a node is selected, we can create all the necessary edges in the initialization of the system, and show them when they are needed. So, normally they would be hidden, but we show them when the user selects a node.$/;"	section	line:312
How do you perceive the application for pattern finding	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/evaluation.tex	/^During the interviews, we also asked if using a standalone headset like the Oculus Quest is advantageous. Respondents 1 and 5 respondents said that it is. The reason why it is advantageous is that it is easier to use since you don't need cables and you can also stand and use it anywhere you want. It is also easy if you can walk around in order to explore the network, according to respondent 5. On the other hand, two respondents (2 and 3) claimed that they prefer to use this kind of visualization tool while sitting. The rest of the respondents didn't consider it relevant.$/;"	subsubsection	line:406
Discussion	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/evaluation.tex	/^\\end{itemize}$/;"	subsubsection	line:438
Translation of the network	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/genenetvr.tex	/^In addition to the teleportation, it is also possible to rotate to the left or to the right with the Oculus controllers so that the user doesn't have to rotate the head to look around in the scene. This action is triggered using the thumbstick on the left hand (See 1. Snap rotation in Figure \\ref{fig:oculus_quest_inputs}). By moving the thumbstick to the left side, the camera will rotate 45$^{\\circ}$ to the left side, and 45$^{\\circ}$ to the right side if the user moves it to the right side. A black transition is also used in this case before the rotation happens to avoid motion sickness, for the same reason as in the teleportation technique.$/;"	subsubsection	line:66
Zooming in the network	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/genenetvr.tex	/^To translate the network in GeneNet VR, the user needs to press on the hand trigger from the right controller (see “3. Translate network” in Figure \\ref{fig:oculus_quest_inputs}). Then the user needs to keep holding this trigger down and move the hand to the direction to which we want the network to move to (see Figure \\ref{fig:translation}). This intuitive approach feels like we are just pulling from a rope tied to the network and we just move it to the direction we want.$/;"	subsubsection	line:78
Interaction with the nodes	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/genenetvr.tex	/^In Figure \\ref{fig:scaling} there is a visual example of how the zooming works using the Oculus controllers. In this example the user is stretching the hands out in order to make the network bigger. The user starts in an initial position, then holds the zooming triggers from both controllers and then moves the hands out. If we wanted to make the network smaller we would do the opposite action, by contracting the hands to the inside.$/;"	subsubsection	line:94
Node relationships	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/genenetvr.tex	/^GeneNet VR provides also information about the data that is being displayed. The user can interact with the nodes of the network to obtain information about each of them. In our example, the nodes represent genes and the user might be interested in knowing which gene name corresponds to a specific node. The action that we need to do to obtain the name of the gene is to get close with the right controller to the node that we are interested in and press the “5. Select node” index trigger on the right controller (see Figure \\ref{fig:oculus_quest_inputs}). When we press this trigger, we can select a node from the network. By selecting a node, we will get the name of that gene node that will be displayed in a rendered text, and we will also visualize the edges from this node to other nodes. The node is selected with an algorithm that searches for the node closest to our right controller.$/;"	subsubsection	line:97
Filtering information in the network	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/genenetvr.tex	/^GeneNet VR provides some features that help in the process of visualization and interaction with the network. They have a complementary purpose, and they don't influence much in the scalability of the system.$/;"	subsubsection	line:168
Network morphing	/Users/alvaromartinezfernandez/Documents/UiT/Masteroppgave/thesis/chapters/genenetvr.tex	/^We have built a 2 dimensional menu in Unity, see Figure \\ref{fig:filtering}, to filter the data in our example network. We use checkboxes for the filtering. From a starting point, all the boxes are checked, and if the user wants to hide a part from the visualization it is done by unchecking the box. To show the filtering menu we need to press on the menu button from the left controller, see the “2. Filter menu” in Figure \\ref{fig:oculus_quest_inputs}. The to check or uncheck the boxes we need to use the A button from the right controller, named “6. Select item”, see Figure \\ref{fig:oculus_quest_inputs}.$/;"	subsubsection	line:180
